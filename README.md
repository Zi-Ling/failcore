# FailCore

**When your agent breaks, you don't need better prompts â€” you need to know what it actually did.**

FailCore is a **minimal execution tracing and failure analysis toolkit** for LLM agents.

It doesn't care how agents "think" â€” it cares about: **what was executed, why it failed, and can we replay it.**

> âš ï¸ **Beta (0.1.x)** â€” core CLI & trace format are stable; minor APIs may change.

---

## Why FailCore?

**Traditional Agent Frameworks:**
- âŒ No visibility into which tool call failed
- âŒ Can't track agent permission violations
- âŒ LLM output drift (text instead of JSON) goes undetected
- âŒ Can't replay execution for root cause analysis

**FailCore Solution:**
- âœ… **Auto-tracing** â€” Every tool call logged to `.jsonl` trace
- âœ… **Policy enforcement** â€” Agents can't escape sandbox boundaries
- âœ… **Contract validation** â€” Auto-detect output type drift (TEXT vs JSON)
- âœ… **Blackbox replay** â€” Audit execution without re-running LLM

---

## Quick Start

### Install (PyPI)

```bash
pip install failcore
```

> Pre-releases (TestPyPI):
> ```bash
> pip install -i https://test.pypi.org/simple >   --extra-index-url https://pypi.org/simple >   failcore
> ```

### Try the Demo (Recommended)

```bash
failcore sample
failcore show
```

### Minimal API

```python
from failcore import Session

with Session() as session:
    session.register("divide", lambda a, b: a / b)
    r = session.call("divide", a=6, b=0)

print(r.status.value)
print(r.error.message if r.error else None)
```

### View Execution Records

```bash
failcore list
failcore show                 # last run
failcore replay run <trace>    # report/mock
failcore replay diff <trace>
```

---

## Three Core Capabilities

### 1. Sandbox Policy (Permission Boundaries)

```python
from failcore import Session, presets
import os

with Session(policy=presets.read_only()) as session:
    session.register("delete_cache", os.remove)
    result = session.call("delete_cache", path="/tmp/cache.db")
    # âŒ Blocked by policy â€” never executes
```

### 2. Contract Validation (Output Drift Detection)

```python
from failcore import Session

with Session() as session:
    @session.tool
    def fetch_user() -> dict:  # Expected: dict
        return "Here is the data: {name: 'Alice'}"  # âŒ Returned text

    r = session.call("fetch_user")
    # Auto-detected: r.output.kind == "TEXT" (expected JSON)
```

### 3. Trace Replay (Forensic Analysis)

```bash
# Offline audit â€” no LLM re-run needed
failcore replay run <trace> --mode report

# Compare historical vs current rules/outputs
failcore replay diff <trace>
```

---

## LangChain Integration (Optional)

Install with LangChain support:

```bash
pip install "failcore[langchain]"
```

```python
from failcore.adapters.langchain import create_langchain_toolkit

toolkit = create_langchain_toolkit(session)
# All agent tool calls auto-logged to trace
```

---

## Who Is This For?

- ğŸ”§ Building production-grade agent systems
- ğŸ› Debugging complex multi-step execution chains
- ğŸ”’ Enforcing agent permission boundaries
- ğŸ“Š Offline failure root cause analysis

---

## License

MIT
